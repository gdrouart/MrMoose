{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'astropy.modeling.physical_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-67802f6b6220>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0memcee\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfitting\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraphics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_files\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MrMoose/MrMoose/utils/fitting.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \"\"\"\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmm_utilities\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MrMoose/MrMoose/utils/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#from astropy import analytic_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mastropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphysical_models\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mampm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mastropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'astropy.modeling.physical_models'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import pickle as pickle\n",
    "import yaml\n",
    "import emcee\n",
    "\n",
    "from utils import fitting as ft\n",
    "from utils import graphics as gp\n",
    "from utils import read_files as rd\n",
    "from utils import mm_utilities as ut\n",
    "from utils import analysis as an\n",
    "from utils.models import *\n",
    "from utils.fitting import *\n",
    "\n",
    "# testing\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fake_source_ex1.fit', 'rb') as input:\n",
    "    fit_struct = yaml.load(input)\n",
    "ut.add_filenames(fit_struct)\n",
    "data_struct = rd.read_data(fit_struct['source_file'], [fit_struct['unit_flux'], fit_struct['unit_obs']])\n",
    "model_struct = rd.read_mod_file(fit_struct['model_file'])\n",
    "filter_struct = rd.read_filters(data_struct)\n",
    "\n",
    "rd.set_init_guess(model_struct)\n",
    "rd.set_param_start(model_struct)\n",
    "\n",
    "detection_mask = []\n",
    "for i in range(len(data_struct)):\n",
    "    detection_mask.append(data_struct[i]['det_type'] == 'd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprior(theta, models):\n",
    "#     print(theta.shape, theta)\n",
    "    tmin = ut.flatten_model_keyword(models, 'min')\n",
    "    tmax = ut.flatten_model_keyword(models, 'max')\n",
    "    # trick to get the dimension of table right...\n",
    "    theta = theta.flatten()\n",
    "\n",
    "    list_prior = [0.0 if tmin[i] < theta[i] < tmax[i] else -np.inf for i in range(len(tmin))]\n",
    "#     print(list_prior)\n",
    "    return sum(list_prior)\n",
    "\n",
    "def lnprior_un(theta, models):\n",
    "    # print(theta.shape, theta)\n",
    "    tmin = ut.flatten_model_keyword(models, 'min')\n",
    "#     print('tmin',tmin)\n",
    "#     print('theta',theta)\n",
    "    # tmax = ut.flatten_model_keyword(models, 'max')\n",
    "    # trick to get the dimension of table right...\n",
    "    theta = theta.flatten()\n",
    "    list_prior=np.zeros(tmin.size)\n",
    "    list_prior[0] = theta[0]*10.-25.\n",
    "    list_prior[1] = theta[1]*2.-2.\n",
    "#     print('list_prior',list_prior)\n",
    "    return list_prior\n",
    "\n",
    "def lnprior_un2(theta, models):\n",
    "    tmin = ut.flatten_model_keyword(models, 'min')\n",
    "    tmax = ut.flatten_model_keyword(models, 'max')\n",
    "    theta = theta.flatten()\n",
    "    list_prior=np.zeros(tmin.size)\n",
    "#     print('theta',theta)\n",
    "    for i,elem in enumerate(theta):\n",
    "#         print(i,elem,tmax[i],tmin[i])\n",
    "        list_prior[i] = elem*np.abs(tmax[i]-tmin[i])+tmin[i]\n",
    "#     print('prior',list_prior)\n",
    "    return list_prior\n",
    "\n",
    "def lnprob(theta, fit_struct, data, filters, models, detection_mask):\n",
    "    lp = lnprior(theta, models)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnlike(theta, fit_struct, data, filters, models, detection_mask)\n",
    "\n",
    "def lnlike(theta, fit_struct, data, filters, param, detection_mask):\n",
    "    theta = theta.flatten()\n",
    "    ub = 0\n",
    "    for i in range(len(param)):\n",
    "        lb = ub\n",
    "        ub = param[i]['dim'] + ub\n",
    "        param[i]['current'] = theta[lb:ub]\n",
    "\n",
    "    model_data = []\n",
    "    number_of_component = []\n",
    "    detections = []\n",
    "    model_detections = []\n",
    "    upper_limits = []\n",
    "    model_upper_limits = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        number_of_component.append(list(map(int, str.split(data[i]['component_number'][0], ','))))\n",
    "        min_tmp = np.log10(min(data[i]['lambda0'])*0.01)\n",
    "        max_tmp = np.log10(max(data[i]['lambda0'])*100.)\n",
    "        xscale = 10**np.linspace(min_tmp, max_tmp, 2000)\n",
    "        temp = np.zeros(2000)\n",
    "\n",
    "        for j in range(len(number_of_component[i])):\n",
    "#             print(param[number_of_component[i][j]]['current'])\n",
    "            if fit_struct['redshift'][number_of_component[i][j]] >= 0:\n",
    "#                 print(\"pass positive, \", param[number_of_component[i][j]]['func'])\n",
    "                temp2 = globals()[param[number_of_component[i][j]]['func']]\\\n",
    "                    (xscale, param[number_of_component[i][j]]['current'], fit_struct['redshift'][number_of_component[i][j]])\n",
    "            else:\n",
    "                #print \"pass negative, \", param[number_of_component[i][j]]['func']\n",
    "                temp2 = globals()[param[number_of_component[i][j]]['func']]\\\n",
    "                    (xscale, param[number_of_component[i][j]]['current'])\n",
    "            temp += temp2\n",
    "\n",
    "        # Making the sum of models to go through filters\n",
    "        temp_mod_filter = np.empty(data[i]['lambda0'].size)\n",
    "\n",
    "        for j, elem in enumerate(filters[i]['name']):\n",
    "            temp_mod_filter[j] = ut.integrate_filter(xscale, temp, filters[i]['wav'][j][:], filters[i]['trans'][j][:])\n",
    "\n",
    "        model_data.append(temp_mod_filter)\n",
    "\n",
    "\n",
    "        # splits data in detection or upper limits, since you need to send these ones to different chi2 functions\n",
    "        detections.append(data[i][detection_mask[i]])\n",
    "        model_detections.append(model_data[i][np.array(detection_mask[i])])\n",
    "\n",
    "        upper_limits.append(data[i][~detection_mask[i]])\n",
    "        model_upper_limits.append(model_data[i][~np.array(detection_mask[i])])\n",
    "\n",
    "\n",
    "    # calculate the total chi2 which is the main part of this function\n",
    "    chi2_classic = []\n",
    "    chi2_modified = []\n",
    "\n",
    "    for i in range(len(detections)):\n",
    "        chi2_classic.append(calc_chi2(detections[i]['flux'],\n",
    "                                      detections[i]['flux_error'],\n",
    "                                      model_detections[i]))\n",
    "\n",
    "    for i in range(len(upper_limits)):\n",
    "        chi2_modified.append(calc_chi2_mod(upper_limits[i]['flux'],\n",
    "                                           upper_limits[i]['flux_error'],\n",
    "                                           model_upper_limits[i]))\n",
    "\n",
    "    return -(sum(chi2_classic)+sum(chi2_modified))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model_struct)\n",
    "#print(filter_struct)\n",
    "def wrap_prior(*args):\n",
    "#    print('passed prior')\n",
    "    #print(*args)\n",
    "    return lnprior_un2(*args, model_struct)\n",
    "def wrap_likelihood(*args):\n",
    "    # print('passed likelihood')\n",
    "    # print(*args)\n",
    "    return lnlike(*args, fit_struct, data_struct, filter_struct, model_struct, detection_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultranest\n",
    "param_names=ut.flatten_model_keyword(model_struct,'param')\n",
    "dummy_name=['Norm','alpha']\n",
    "#    sampler = ft.fit_source(fit_struct, data_struct, filter_struct, model_struct,fit_method='emcee')\n",
    "sampler = ultranest.ReactiveNestedSampler(dummy_name, wrap_likelihood, wrap_prior)\n",
    "# ultranest.ReactiveNestedSampler?\n",
    "# an.find_stats_fit(sampler, model_struct, fit_struct, data_struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "result=sampler.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.plot_corner()\n",
    "sampler.plot_run()\n",
    "sampler.plot_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultranest.plot import PredictionBand\n",
    "x = 10**np.linspace(7.8, 10., 400)\n",
    "band = PredictionBand(x)\n",
    "band_lo = PredictionBand(x)\n",
    "band_hi = PredictionBand(x)\n",
    "\n",
    "for params in sampler.results['samples'][:40]:\n",
    "    y = sync_law(x,params,0.0)\n",
    "#     slope, offset, scatter = params\n",
    "#     y = (x - 10) * slope + offset\n",
    "    band.add(y)\n",
    "\n",
    "    # indicate intrinsic scatter\n",
    "#     band_hi.add(10**(y + scatter))\n",
    "#     band_lo.add(10**(y - scatter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_struct[0]['lambda0'],data_struct[0]['flux'],marker='D',ls='none')\n",
    "plt.xscale('log');plt.yscale('log')\n",
    "band.shade(color='k', alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.results['samples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toto=ut.flatten_model_keyword(model_struct,'param')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
